#' Function to create a map for row IDs of a data frame
#'
#' This function creates a map for row IDs of its input data frame.
#' In context of the USBseq package the sequence IDs can be used as alternate short identifiers for each unique sequence.
#' @param countTable the table generated by createCountTableFromFastQs
#' @keywords sequence IDs
#' @export
#' @examples
#' in_dir <- system.file("extdata", package = "USBseq")
#' countTable <- createCountTableFromFastQs(in_dir)
#' map <- createMap(countTable)

createMap <- function(countTable) {
  map <- as.data.frame(paste("seq_", c(1:nrow(countTable)) , sep=""))
  row.names(map) <- row.names(countTable)
  names(map) <- c("seq_id")
  return(map)
}

#' Function to filter a count table
#'
#' This function pre-filters a count table of sequences using additional information on sample conditions.
#' Filtering is especially useful in context of the USBseq package because sequence based count tables are generally very large.
#' Sequences are kept if both groups have an average sequence count of at least 10 or if one of both group has zero counts for all samples.
#' @param countTable the table generated by createCountTableFromFastQs
#' @param phenofile data frame with sample IDs as row.names and column 'condition'. Sample IDs must be identical to those in countTable.
#' @keywords filtering
#' @export
#' @examples
#' in_dir <- system.file("extdata", package = "USBseq")
#' countTable <- createCountTableFromFastQs(in_dir)
#' phenoInfo <- read.table(system.file("extdata", "condition.tsv", package = "USBseq"), header=T, row.names=1)
#' countTableFiltered <- filterLowExp(countTable, phenoInfo)

filterLowExp<-function(countData,pheno){
  #Get Group Means
  groups <- unique(pheno$condition)
  if(! length(groups) == 2) {
    stop(paste(phenofile," is invalid! Please provide a file with the column 'condition' including two different values."),call.=F)
  }
  for(type in groups){
    cols  <- row.names(pheno)[which(pheno$condition==type)]
    subset <- countData[,cols]
    countData <- cbind(countData,rowMeans(subset))
  }
  #Keep sequences where both groups have an average ReadCount of >10 or one group as no expression
  cond1 = countData[ncol(countData)]>=10 & countData[ncol(countData)-1]>=10
  cond2 = countData[ncol(countData)]==0 & countData[ncol(countData)-1]>1
  cond3 = countData[ncol(countData)]>1 & countData[ncol(countData)-1]==0
  countData = countData[(cond1|cond2|cond3) ,c(1:(ncol(countData)-2))]

  return(countData)
}

#' Function to merge DEA, blast result
#'
#' @param deResult result of differential expression analysis (columns log2FoldChange, pvalue, IHWPval are required)
#' @param countStats result of getConditionCountStats function
#' @param blastResult result of blast function
#' @param clustResult result of clustering function
#' @param map data frame with sequences as row names and sequence IDs in first column
#' @keywords generating summary tables
#' @export
#' @examples
#' summary_blast <- mergeResults(sigResults,blastResult=blastResult,map=map)
#' summary_clust <- mergeResults(sigResults,clustResult=clustResult,map=map)
#' summary <- mergeResults(sigResults, blastResult, clustResult, map)

mergeResults <- function(deResult=NULL, countStats=NULL, blastResult=NULL, clustResult=NULL, map) {

  if(is.null(deResult) && is.null(countStats) && is.null(blastResult) && is.null(clustResult)) {
    stop("mergeResults requires at least deResult, countStats, blastResult or clustResult!")
  }

  res <- map
  colnames(res) <- c("SequenceID")
  res$sequence <- row.names(map)

  if(!is.null(deResult)) {
    sigResults <- deResult[c("log2FoldChange","pvalue","IHWPval")]
    colnames(sigResults) <- c("Log2FoldChange","Pvalue","IHWPvalue")
    sigResults$SequenceID <- map[row.names(sigResults),1]
    sigResults$sequence <- row.names(sigResults)
    res <- sigResults
  }

  if(!is.null(countStats)) {
    countStats$sequence <- row.names(countStats)
    res <- plyr::join(res, countStats, type = "inner")
  }

  if(!is.null(clustResult)) {
    res <- plyr::join(res, clustResult, type = "full")
  }

  if(!is.null(blastResult)) {
    blastResult <- blastResult[c("qseqid", "sseqid", "length", "evalue")]
    colnames(blastResult) <- c("SequenceID","sseqid","Length","BlastEvalue")
    res <- plyr::join(res, blastResult, type = "full")
    group <- data.frame(FeatureList=c(by(res$sseqid, res$sequence, function(x)paste(x, collapse=","))))
    group$sequence <- row.names(group)
    group <- plyr::join(group, res, type = "full", match="first")
    group <- group[-which(names(group)=="sseqid")]
    # move featureList to last column
    group <- group[,c(which(names(group)!="FeatureList"),which(names(group)=="FeatureList"))]
    # move sequenceID to first column
    group <- group[,c(which(names(group)=="SequenceID"),which(names(group)!="SequenceID"))]
    group$Length <- nchar(group$sequence)
    row.names(group) <- group$sequence
    res <- group[-which(names(group)=="sequence")]
  }

  if("Pvalue" %in% colnames(res)) {
    res <- res[order(res$Pvalue),]
  }
  return(res)
}

#' Function to compute mean and sd of normalized counts for each condition
#'
#' @param countData table of (normalized) counts per sequence
#' @param phenoData data frame with sample names as rownames and assigned condition in first column
#' @keywords count statistics
#' @export
#' @examples

getConditionCountStats<-function(countData,phenoData){

  pheno <- phenoData
  #Get Group Means
  groups = unique(pheno$condition)
  for(type in groups){
    cols  = row.names(pheno)[which(pheno$condition==type)]
    subset= countData[,cols]
    countData=cbind(countData,rowMeans(subset),data.frame(apply(subset,1,sd)))
    names(countData)[ncol(countData)-1]=paste("NormCounts",type,"Mean",sep="_")
    names(countData)[ncol(countData)]=paste("NormCounts",type,"Sd",sep="_")
  }
  index=length(groups)*2
  #Return only Mean & Sd columns
  return(countData[,c((ncol(countData)-index+1):ncol(countData))])
}

#' Function to add counts of different feature classes
#'
#' @param mergedResult summary table including blast results
#' @param featureClasses List of features representing classes to be counted.
#' Features can be defined as regular expressions, as described in \link[stringi]{stringi-search-regex}.
#' @keywords feature counting
#' @export
#' @examples

addCountsOfFeatureClasses<- function(mergedResult, featureClasses) {
  if(!("FeatureList" %in% names(mergedResult))) stop('Feature classes can only be counted if blast results have been merged to DE results!')
  res <- mergedResult
  v_features <- strsplit(paste(mergedResult$FeatureList),",")
  sum <- 0
  for(i in featureClasses) {
    res[i] <- stringr::str_count(string=v_features, i)
    sum <- sum + res[[i]]
  }
  res$"Other" <- as.numeric(lapply(v_features, function(x) length(x[! x == "NA" ]))) - sum
  res <- res[,c(which(names(res)!="FeatureList"),which(names(res)=="FeatureList"))]

  if("Pvalue" %in% colnames(res)) {
    res <- res[order(res$Pvalue),]
  }
  return(res)
}

#' Function to write summary tables and fasta files for USBseq result
#'
#' @param summaryTable summary table generated by mergeResults function (requires blast result)
#' @param outDir directory for summary files (tsv tables and fasta files)
#' @keywords summary
#' @export
#' @examples

writeSummaryFiles <- function(summaryTable, outDir) {
  summaryTable$Sequence=row.names(summaryTable)
  summaryTable <- summaryTable[,c(ncol(summaryTable),1:ncol(summaryTable)-1)]
  write.table(summaryTable, paste(outDir, "SummaryTable.tsv", sep="/"), sep="\t", quote=F, row.names=F, col.names=T)

  filtered <- summaryTable[!summaryTable$FeatureList=="NA",]
  write.table(filtered, paste(outDir, "SummaryTable_withBlast.tsv", sep="/"), sep="\t", quote=F, row.names=F, col.names=T)

  filtered = filtered[filtered$Length<36,]
  sequences_withBlast<-paste(paste(">",filtered$SequenceID,sep=""),row.names(filtered),sep="\n")
  write.table(sequences_withBlast, paste(out_dir,"SummaryTable_withBlast.35L.fasta",sep="/"),quote=F,row.names=F,col.names=F)

  filtered = summaryTable[summaryTable$FeatureList=="NA" | is.na(summaryTable$FeatureList),]
  write.table(filtered, paste(out_dir,"SummaryTable_noBlast.tsv",sep="/"), sep="\t", quote=F,row.names=F,col.names=T)

  filtered = filtered[filtered$Length<36,]
  sequences_noBlast<-paste(paste(">",filtered$SequenceID,sep=""),row.names(filtered),sep="\n")
  write.table(sequences_noBlast, paste(out_dir,"SummaryTable_noBlast.35L.fasta",sep="/"),quote=F,row.names=F,col.names=F)
}

#' Function to get sequences as a vector of fasta IDs and sequences
#'
#' @param sigResults resulting table of differential expression analysis with significant sequences as row names
#' @param map map of sequences to sequence IDs used as IDs in fasta
#' @keywords fasta
#' @export
#' @examples

sequencesAsFasta <- function(sigResults, map) {
  res <- as.vector(rbind(paste(">",map[row.names(sigResults),1],sep=""),row.names(sigResults)))
  return(res)
}

#' Function to remove temporary files after pipeline execution
#'
#' @param outDir output folder
#' @keywords clean-up
#' @export
#' @examples

deleteTmp <- function(outDir){
  tmp <- paste(out_dir,"sig_sequences.fa",sep="/")
  if(file.exists(tmp)){
    file.remove(tmp)
  }
}


