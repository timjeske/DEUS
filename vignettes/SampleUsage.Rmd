---
title: "Run DEUS"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Run DEUS}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

### (Optional) preprocessing of FASTQ files

Before applying DEUS we strongly recommend to trim your input FASTQ files. 
[Trim Galore](https://www.bioinformatics.babraham.ac.uk/projects/trim_galore/) can be used to do adapter and quality trimming. The `--max_length` parameter should be set to (read length - 1) to remove non-small RNA sequences.

```bash
# remove adapters (automatically recognized by Trim Galore)
/software/trim_galore_v0.x.x/trim_galore -q 0 --length 16 --max_length 49 $in_file -o $out_dir
# quality trimming (use dummy adapter to suppress adapter trimming)
/software/trim_galore_v0.x.x/trim_galore -q 20 --length 1 -a CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC --stringency 50 $in_file -o $out_dir
```

### Installing DEUS

You can install DEUS from GitHub with:

```{r gh-installation, eval=FALSE}
if (!require("devtools")) install.packages("devtools", repos='http://cran.us.r-project.org')
devtools::install_github("timjeske/DEUS")
library(DEUS)
```

Alternatively, you can install DEUS from a local copy.

First, you need to unzip it:

```bash
unzip DEUS-master.zip
```

Then you can install it in R:

```{r, eval=FALSE}
if (!require("devtools")) install.packages("devtools", repos='http://cran.us.r-project.org')
devtools::install_local("./DEUS-master")
library(DEUS)
```

### Setting parameters

Before running the individual steps of the DEUS pipeline it is helpful to set all required parameters.
The `in_dir` is the folder where the (trimmed) FASTQ files are stored. The `phenofile` is the condition file for differential expression analysis (DEA) ([examplary condition file](DEUS.html#preparing-a-condition-file)).
The `out_dir` is the folder where DEA plots, clustering and summary output files will be stored.
To use BLAST, it is necessary to set the [BLAST binary](ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/), your [BLAST database](DEUS.html#preparing-a-blast-database) and the number of threads to be used. 
To cluster resulting sequencing, the [cd-hit-est](http://weizhongli-lab.org/cd-hit/) binary is reuqired.

```{r, eval=FALSE}

in_dir <- "/data/fastq-files/"
phenofile <- "/data/condition.tsv"

out_dir <- "data/results"

blast_exec <- "/software/blast/bin/blastn"
blast_db <- "/data/My_Blast_DB.fa"
blast_ncores <- 2

cd_hit <- "/software/cdhit/cd-hit-est"
```

### Counting unique sequences

To create the count table for differential expression analysis, [createCountTableFromFastQs](../reference/createCountTableFromFastQs.html) counts all unique sequences in each FASTQ file given in your `phenofile`. To remove low expressed sequences and reduce the size of the count table [filterLowExp](../reference/filterLowExp.html) is applied. Sequences are kept if both groups of samples have a default minimum average sequence count of 10 or if one of both groups has zero counts for all samples. It can be useful to store the filtered count table in our output folder as counting takes some time.
```{r, eval=FALSE}
phenoInfo <- read.table(phenofile, header=T, row.names=1, check.names=FALSE)
countTable <- createCountTableFromFastQs(in_dir, phenoInfo=phenoInfo)
countTable <- filterLowExp(countTable, phenoInfo)
write.table(countTable, paste(out_dir,"AllCounts_filtered.tsv",sep="/"), col.names=T, quote=F, sep="\t", row.names=T)
```

### Running differential expression analysis

Differential expression analysis is done by calling the function [runDESeq2](../reference/runDESeq2.html). 
After filtering for significant sequences, a map is created by [createMap](../reference/createMap.html) which assigns a unique identifier to each sequence.
The results of [runDESeq2](../reference/runDESeq2.html) are additionally used as input for [getConditionCountStats](../reference/getConditionCountStats.html) to compute the mean and the standard deviation of the normalized counts for each analyzed conditions.

```{r, eval=FALSE}
design <- ~ condition
deResults <- runDESeq2(countTable, phenoInfo, design, map, out_dir)
sigResults <- deResults$deResult
sigResults <- sigResults[!is.na(sigResults$IHWPval) & sigResults$IHWPval < 0.05,]
map <- createMap(sigResults)

# get count stats
countStats <- getConditionCountStats(deResults$normCounts, phenoInfo)
```

### Running BLAST

To annotate significant sequences they need to transformed to a vector of sequences in FASTA style by using [sequencesAsFasta](../reference/sequencesAsFasta.html). Afterwards BLAST is executed by [runBlast](../reference/runBlast.html).
```{r, eval=FALSE}
sigSeqFasta <- sequencesAsFasta(sigResults,map)
blastResult <- runBlast(blast_exec, blast_db, blast_ncores, sigSeqFasta)
```

### Run clustering

The CD-Hit algorithm is executed via [runClustering](../reference/runClustering.html).
```{r, eval=FALSE}
  clustResult <- runClustering(cd_hit, sigSeqFasta, out_dir, 0.9, 0.9, 9, map)
```

### Merging the results

Finally, the group-wise mean and standard deviation of the normalized counts, the results of DEA, BLASTing and clustering are merged together by [mergeResults](../reference/mergeResults.html).
Additionally, [addCountsOfFeatureClasses](../reference/addCountsOfFeatureClasses.html) is used to count the number of BLAST hits grouped by user defined feature classes.
Summary files are then written to the `out_dir` by [writeSummaryFiles](../reference/writeSummaryFiles.html).
```{r, eval=FALSE}
classes <- c("tRNA","[Hh]sa","^U")
summary <- mergeResults(sigResults, countStats, blastResult, clustResult, map)
summary <- addCountsOfFeatureClasses(summary, classes)
writeSummaryFiles(summary, out_dir)

```
___

### Expression analysis using sequence clusters

In addition to the default DEUS pipeline, we developed an adjusted approach that aggregates sequence counts for each sequence cluster and uses this information to find differentially expressed sequence clusters. By some small adjustments, the cluster expression analysis can be included to the default DEUS pipeline.

Instead of creating the sequence map for differentially expressed sequences only, the sequence/id map will be created using [createMap](../reference/createMap.html) on the raw input sequences since all will be used for clustering.
```{r, eval=FALSE}
# create count table, create sequence to sequenceID map
pheno_info <- read.table(phenofile, header=T, row.names=1, check.names=FALSE)
count_table <- createCountTableFromFastQs(in_dir, pheno_info=pheno_info)
#Create map with all sequences
map <- createMap(count_table)

```

Afterwards, all sequences can be clustered. Based on the clustering results, the sum of sequence counts will be created for each cluster.
```{r, eval=FALSE}
#Get all sequences as one fasta file
allSeqFasta <- sequencesAsFasta(count_table,map)
#Cluster them
clustResult<-runClustering(cd_hit, allSeqFasta, out_dir, 0.9, 0.9, 9, map)
#Aggregate counts by cluster
cl_counts <- mergeAndAggregate(map,count_table,clustResult)

```

The resulting count matrix can be used as input for the usual DE analysis. 
```{r, eval=FALSE}
# run differential expression analysis on clusters
design <- ~ condition
cl_deResults <- runDESeq2(cl_counts, pheno_info, design, out_dir = out_dir)
cl_sigResults <- cl_deResults$deResult
```

Next, we continue with the standard approach and calculated DE results for unique sequences

```{r, eval=FALSE}
#Filter lowexpressed but only for single seq approach
count_table <- filterLowExp(count_table, pheno_info)
write.table(count_table, paste(out_dir,"AllCounts_filtered.tsv",sep="/"), col.names=T, quote=F, sep="\t", row.names=T)

# run differential expression analysis
deResults <- runDESeq2(count_table, pheno_info, design, out_dir=out_dir)
sigResults <- deResults$deResult

# get count stats
countStats <- getConditionCountStats(deResults$normCounts, pheno_info)
```

Subsequently, both results can be merged into a single data frame. Based on the individual and cluster pvalues, sequences can be filtered to detect potential interesting cases.
```{r, eval=FALSE}
#Merge sigResults and cl_sigResults
sigResults <- mergeSingleAndClusterResults(cl_sigResults,clustResult,sigResults,map)

sigResults <- sigResults[((!is.na(sigResults$IHWPval) & sigResults$IHWPval < 0.05) | (!is.na(sigResults$Cl_IHWPval) & sigResults$Cl_IHWPval < 0.05)),]
```

Finally, we continue with the default pipeline and add annotation using Blast. All results are merged and written into summary files
```{r, eval=FALSE}
#Get sequences for blast
sigSeqFasta <- sequencesAsFasta(sigResults,map)
# run blast
if(file.exists(blast_exec)) {
  blastResult <- runBlast(blast_exec, blast_db, blast_ncores, sigSeqFasta)
} else {
  blastResult <- read.table(blast_int, header=T, sep="\t")
}

# merge results
classes <- c("tRNA","[Hh]sa","^U")
summary <- mergeResults(sigResults, countStats, blastResult, clustResult, map)
summary <- addCountsOfFeatureClasses(summary, classes)
writeSummaryFiles(summary, out_dir)
```



