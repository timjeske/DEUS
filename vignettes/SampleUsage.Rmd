---
title: "Run DEUS"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Run DEUS}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

### (Optional) preprocessing of FASTQ files

Before applying DEUS we strongly recommend to trim your input FASTQ files. 
[Trim Galore](https://www.bioinformatics.babraham.ac.uk/projects/trim_galore/) can be used to do adapter and quality trimming. The `--max_length` parameter should be set to (read length - 1) to remove non-small RNA sequences.

```bash
# remove adapters (automatically recognized by Trim Galore)
/software/trim_galore_v0.x.x/trim_galore -q 0 --length 16 --max_length 49 $in_file -o $out_dir
# quality trimming (use dummy adapter to suppress adapter trimming)
/software/trim_galore_v0.x.x/trim_galore -q 20 --length 1 -a CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC --stringency 50 $in_file -o $out_dir
```

### Installing DEUS

You can install DEUS from GitHub with:

```{r gh-installation}
if (!require("devtools")) install.packages("devtools", repos='http://cran.us.r-project.org')
devtools::install_github("timjeske/DEUS")
library(DEUS)
```

Alternatively, you can install DEUS from a local copy.

First, you need to unzip it:

```bash
unzip DEUS-master.zip
```

Then you can install it in R:

```{r, eval=FALSE}
if (!require("devtools")) install.packages("devtools", repos='http://cran.us.r-project.org')
devtools::install_local("./DEUS-master")
library(DEUS)
```

### Setting parameters

Before running the individual steps of the DEUS pipeline it is helpful to set all required parameters.
The `in_dir` is the folder where the (trimmed) FASTQ files are stored. The `phenofile` is the condition file for differential expression analysis (DEA) ([examplary condition file](DEUS.html#preparing-a-condition-file)).
The `out_dir` is the folder where DEA plots, clustering and summary output files will be stored.
To use BLAST, it is necessary to set the [BLAST binary](ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/), your [BLAST database](DEUS.html#preparing-a-blast-database) and the number of threads to be used. 
To cluster resulting sequencing, the [cd-hit-est](http://weizhongli-lab.org/cd-hit/) binary is reuqired.

```{r}
# load data delivered with the package
in_dir <- system.file("extdata", package = "DEUS")
phenofile <- system.file("extdata", "condition.tsv", package = "DEUS")
blast_db <-system.file("extdata", "blastdb/DASHR_subset.fa", package = "DEUS")
blast_int <- system.file("extdata", "results/blast_result_sig_sequences.tsv", package="DEUS")
clust_int <- system.file("extdata", "results/clust_result_sig_sequences.tsv", package="DEUS")

out_dir <- "~/tmp"
blast_ncores <- 2
# leave paths empty if not yet installed, intermediate results will be used for testing purposes
blast_exec <- ""
cd_hit <- ""

```

### Counting unique sequences

To create the count table for differential expression analysis, [createCountTableFromFastQs](../reference/createCountTableFromFastQs.html) counts all unique sequences in each FASTQ file given in your `phenofile`. To remove low expressed sequences and reduce the size of the count table [filterLowExp](../reference/filterLowExp.html) is applied. Sequences are kept if both groups of samples have a default minimum average sequence count of 10 or if one of both groups has zero counts for all samples. It can be useful to store the filtered count table in our output folder as counting takes some time. In addtion, a map is created by [createMap](../reference/createMap.html) which assigns a unique identifier to each sequence.
```{r, eval=TRUE}
pheno_info <- read.table(phenofile, header=T, row.names=1, check.names=FALSE)
count_table <- createCountTableFromFastQs(in_dir, pheno_info=pheno_info)
count_table <- filterLowExp(count_table, pheno_info)
map <- createMap(count_table)
write.table(count_table, paste(out_dir,"AllCounts_filtered.tsv",sep="/"), col.names=T, quote=F, sep="\t", row.names=T)
```

### Running differential expression analysis

Differential expression analysis is done by calling the function [runDESeq2](../reference/runDESeq2.html). 
Results are filtered using a 0.05 Pvalue-Cutoff. The significant sequences are subsequently stored in a FASTA file for BLAST annotation using [sequencesAsFasta](../reference/sequencesAsFasta.html).
The results of [runDESeq2](../reference/runDESeq2.html) are additionally used as input for [getConditionCountStats](../reference/getConditionCountStats.html) to compute the mean and the standard deviation of the normalized counts for each analyzed conditions.

```{r, eval=TRUE}
design <- ~ condition
de_results <- runDESeq2(count_table, pheno_info, design, out_dir=out_dir)
sig_results <- de_results$de_result
sig_results <- sig_results[!is.na(sig_results$IHWPvalue) & sig_results$IHWPvalue < 0.05,]
sig_seq_fasta <- sequencesAsFasta(sig_results,map)

# get count stats
count_stats <- getConditionCountStats(de_results$norm_counts, pheno_info)
```

### Running BLAST
The sequences are now annotated using BLAST by executing [runBlast](../reference/runBlast.html).
In our example, we load pre-compiled data.
```{r, eval=TRUE}
#blast_result <- runBlast(blast_exec, blast_db, blast_ncores, sig_seq_fasta)blastResult <- runBlast(blast_exec, blast_db, 
blast_result <- read.table(blast_int, header=T, sep="\t")
```

### Run clustering

The CD-Hit algorithm is executed via [runClustering](../reference/runClustering.html). For this manual, we will load available exmaple data again.
```{r, eval=TRUE}
  #clust_result <- runClustering(cd_hit, sig_seq_fasta, out_dir, identity_cutoff=0.9, length_cutoff=0.9, wordlength=9, map)
  clust_result <- read.table(clust_int, header=T, sep="\t")
  rownames(clust_result) <- clust_result$SequenceID
```

### Merging the results

Finally, the group-wise mean and standard deviation of the normalized counts, the results of DEA, BLASTing and clustering are merged together by [mergeResults](../reference/mergeResults.html).
Additionally, [addCountsOfFeatureClasses](../reference/addCountsOfFeatureClasses.html) is used to count the number of BLAST hits grouped by user defined feature classes.
Summary files are then written to the `out_dir` by [writeSummaryFiles](../reference/writeSummaryFiles.html).
```{r, eval=TRUE}
classes <- c("tRNA","[Hh]sa","^U")
summary <- mergeResults(sig_results, count_stats, blast_result, clust_result, map)
summary <- addCountsOfFeatureClasses(summary, classes)
writeSummaryFiles(summary, out_dir)

```
___

### Expression analysis using sequence clusters

In addition to the default DEUS pipeline, we developed an adjusted approach that aggregates sequence counts for each sequence cluster and uses this information to find differentially expressed sequence clusters. By some small adjustments, the cluster expression analysis can be included to the default DEUS pipeline.
In this example, we will first load some intermediate CD-Hit and BLAST results.

```{r, eval=TRUE}
#Load some more sample data
blast_int <- system.file("extdata", "results/blast_result_clust_sequences.tsv", package="DEUS")
clust_int <- system.file("extdata", "results/clust_result_clust_sequences.tsv", package="DEUS")
```

Instead of creating the sequence map for differentially expressed sequences only, the sequence/id map will be created using [createMap](../reference/createMap.html) on the raw input sequences since all will be used for clustering.
```{r, eval=TRUE}
# create and filter count table, create sequence to sequenceID map
pheno_info <- read.table(phenofile, header=T, row.names=1, check.names=FALSE)
count_table <- createCountTableFromFastQs(in_dir, pheno_info=pheno_info)

#Create map with all sequences
map <- createMap(count_table)

```

Afterwards, all sequences can be clustered. Based on the clustering results, the sum of sequence counts will be created for each cluster.
```{r, eval=TRUE}
#Get all sequences as one fasta file
all_seq_fasta <- sequencesAsFasta(count_table,map)
#Cluster them
#clust_result <- runClustering(cd_hit, all_seq_fasta, out_dir, identity_cutoff=0.9, length_cutoff=0.9, wordlength=9, map)
clust_result <- read.table(clust_int, header=T, sep="\t")
rownames(clust_result) <- clust_result$SequenceID

#Aggregate counts by cluster
cl_counts <- mergeAndAggregate(map, count_table, clust_result)
```

The resulting count matrix can be used as input for the usual DE analysis. 
```{r, eval=FALSE}
# run differential expression analysis on clusters
design <- ~ condition
cl_de_results <- runDESeq2(cl_counts, pheno_info, design, out_dir = out_dir, prefix = "Cluster")
cl_sig_results <- cl_de_results$de_result
```

Next, we continue with the standard approach and calculated DE results for unique sequences

```{r, eval=FALSE}
#Filter low expressed but only for unique sequences approach
count_table <- filterLowExp(count_table, pheno_info)
write.table(count_table, paste(out_dir,"AllCounts_filtered.tsv",sep="/"), col.names=T, quote=F, sep="\t", row.names=T)

# run differential expression analysis
de_results <- runDESeq2(count_table, pheno_info, design, out_dir=out_dir, prefix = "Sequences")
sig_results <- de_results$de_result

# get count stats
count_stats <- getConditionCountStats(de_results$norm_counts, pheno_info)
```

Subsequently, both results can be merged into a single data frame. Based on the individual and cluster pvalues, sequences can be filtered to detect potential interesting cases.
```{r, eval=FALSE}
#Merge sig_results and cl_sig_results
sig_results <- mergeSingleAndClusterResults(cl_sig_results,clust_result,sig_results,map)
sig_results <- sig_results[((!is.na(sig_results$IHWPval) & sig_results$IHWPval < 0.05) | (!is.na(sig_results$Cl_IHWPval) & sig_results$Cl_IHWPval < 0.05)),]

```

Finally, we continue with the default pipeline and add annotation using Blast. All results are merged and written into summary files
```{r, eval=FALSE}
#Get sequences for blast
sig_seq_fasta <- sequencesAsFasta(sig_results,map)

#Run blast
#blast_result <- runBlast(blast_exec, blast_db, blast_ncores, sig_seq_fasta)
blast_result <- read.table(blast_int, header=T, sep="\t")

# merge results
classes <- c("tRNA","[Hh]sa","^U")
summary <- mergeResults(sig_results, count_stats, blast_result, clust_result, map)
summary <- addCountsOfFeatureClasses(summary, classes)
writeSummaryFiles(summary, out_dir)
```

In order to compare both aproaches, we can also generate a overview about both approaches
```{r, eval=FALSE}
printClusterSummary(summary)
```



